#pragma once
/*
0. DirectX(이하 DX)란?
- 간단히 말하면 그래픽 "엔진"이라 부를 수 있음
좀 더 엄밀히 말하면 API의 일종 = 그래픽을 이용하는 무언가를 만들기 위해 지원된 개발 환경

MS사가 직접 개발해서 Windows 황경에서 동작하도록 만들어둔 API이기 때문에,
Visual Studio를 통해 무언가를 만들기 매우 수월한 엔진이기도 함

DX를 다른 식으로 한 줄로 요약할 경우엔 다음과 같이 이야기할 수 있음 :
"그래픽 파이프라인"을 이용해 코드 상의 자료를 화면에 그래픽으로서 출력하도록 만드는 도구 모음

1. 그래픽 파이프라인
-> DX에서 그래픽을 화면(모니터)에 출력하기 위해 거치는 일련의 과정을 말함

파이프라인(Pipeline) : 프로그래밍에선 한 데이터를 처리하면 그 결과물을 출력하기 마련
그렇게 출력된 결과물을 바로 다음 과정에 집어넣어서 데이터를 다시 처리,
다시 나온 결과물을 그 다음 과정에 집어넣어서...
이를 계속하여 모든 단계를 거칠 떄까지
정해진 여러 단계를 거쳐 최종적인 결과를 도출해내는 과정을 말함

핵심은 직전 단계가 실행된 결과물이 있어야만 그 다음단계를 실행할 수 있다는 점
파이프라인은 이 각 단계 사이에서 데이터가 제대로 흘러갈 수 있도록 짜인 구조를 말한다

이걸 그래픽을 그리는 과정을 통해 보자면

맨 처음 그림을 그리기 위해 작성한 자료
-> 자료 처리과정 1 -> 가곻된 자료 A
-> 자료 처리과정 2 -> 가공된 자료 B
-> ...
-> ...
-> ...
-> 마지막 자료 처리과정 -> 화면에 직접 출력할 수 있게 변형된 자료
-> 화면에 출력

이라는 구조로 흘러가도록 구성된 시스템 구조를 그래픽 파이프라인이라 함


2. 그래픽 파이프라인의 각 단계

참고 주소:
https://learn.microsoft.com/ko-kr/windows/win32/direct3d11/overviews-direct3d-11-graphics-pipeline
위 주소의 사진만을 참고할 것
설명도 적혀있기는 하나, 비전공자가 이해할 수 있을 정도의 난이도로 설명하고 있지 않음

여기서는 위 주소에서 설명하고 있는 내용 중 우리가 직접 다룰 단계에 대해서만 비교적 상세하게 다루며,
나머지는 "이런 게 있다" 정도로만 언급할 예정
-> 또한, 여기서 설명하는 건 2D 기준
3D에서는 여기서 다루는 내용들을 전부 다 다루게 될 지도 모르므로
언젠가는 다 익혀둬야 할 내용이 될 수도 있음
+ 지금의 그래픽 파이프라인은 DX 11버젼 기준
같은 DX라고 해도 버젼에 따라 그 단계가 다르기도 하며
다른 엔진을 사용할 경우 큰 흐름은 비슷할지라도 세세한 것은 전부 다를 수 있으므로
지금 설명하는 건 DX 말고 다른 데서는 그냥 큰 틀에서는 이렇게 흘러간다 정도로만 기억해둘 것

A) Input-Assembler 단계
입력 및 취합 단계 -> 자료를 입력하고 그 자료드를 취합하는 단계
그래픽 구성에 이용할 자료들을 다음 단계로 넘기기 위해,
각 단계에서 사용할 수 있는 규격으로 자료들을 규합하는 과정
=> (우리가) 코딩하는 단계

이 단계에서 그래픽 출력에 필요한 자료들을 입력하며, 그 과정은 전적으로 프로그래머에게 맡기고 있음
-> 추후 진행하기 위해선, 우리가 직접
데이터들을 앞으로의 단계에 사용할 수 있도록 자료의 형식을 구성해줘야 함
이게 우리가 그래픽 파이프라인을 배워야 하는 이유
(다음 단계에서 자료들이 어떻게 쓰이는지를 알아야 그에 맞는 자료구성을 할 수 있을 것이므로)

다음 단계들, 특히 Vertex Shader 등의 단계에서는
자료가 반드시 정해진 규격이어야만 정상적으로 작동하고,
그 규격에서 벗어날 경우엔 아예 처리 자체가 진행되지 않음
(꼭지점 6개 대신 5개를 입력했을 떄 2번째 도형이 아예 출력되지 않았던 것이 그 예시)
그래서, 입력할 자료의 구성을 반드시 우리가 규격에 맞춰줘야 할 필요가 있는 것을
아예 단계로서 명시한 것

B) Vertex Shader(꼭지점/정점 셰이더) 단계
위의 A 단계는 규격에 맞춰서 데이터를 입력했을 뿐,
입력된 데이터는 기본적으로 3D 공간에 있는 내용물을 입력한 것
(우리가 2D 데이터를 다루고 있긴 하나, 실제로는 그냥 Z좌표가 0일 뿐인 3차원 데이터를 이용하는 중)
기본적으로 어느 픽셀에 어느 색이 출력되도록 할 것인지만을 출력할 수 있는 모니터(=2D 그래픽)에 즉각 출력할 수 없다
따라서, 출력하려면 2D 그래픽에 맞도록 이 데이터를 변환시켜줄 필요가 있음

-> 입력된 데이터 그 자체로는 화면 처리를 할 수 없으니
이를 그래픽을 가공하는 데 사용할 수 있는 형태, 그래픽 출력에 필요한 형태로 1차 가공하는 단계

3D 공간에선 그래픽, 즉 한 화면이라는 개념을 성립시키려면
그 3D 공간을 어느 한 점에서 보는 시점이 필요
그래야 하나의 "사진" 혹은 "스크린"이라는 2D공간에 어떤 것이 그려져있을지를 결정할 수 있기 때문

정점 셰이더는 바로 그런, 우리가 입력한 3D 공간의 좌표계들을
"시점 기준의 좌표계"로 변환하는 역할을 맡음
-> 3D 좌표를 2D 좌표로 변환하는 역할을 맡는다



C) Tesselator 단계
(DX11 기준으로는 Hull Shader/Tesselator/Domain Shader/Geometry Shader 등
여러 단계로 나뉘어진 단계이지만, 옛날 기준으로 한 단계였던 것이 세분화된 것인데다
어차피 우리는 이 단계의 내용을 뭉뚱그려 처리할 것이므로 큰 틀 하나로 줄인 것)

3D 그래픽은 그래픽을 구성하는 최소 단위가 Polygon이라는 단위로 구성되어 있음
이 폴리곤의 수가 많으면 많을 수록 최대한 세밀하게 그래픽을 표현 가능

이 단계는 정점 셰이더를 통해 2D 좌표로 1차 가공된 데이터들을 잘게 쪼개서
최대한 많은 수의 폴리곤으로 만드는 단계
(2D에선 직접 손 볼 일이 업성서 우리는 자세하게 다루지 않음)

여기서 폴리곤으로 쪼개는 단위는 픽셀 하나하나 단위에 근접할 수준으로 쪼개는 레벨이라
우리가 미리미리 쪼개서 입력하는 등은 거진 불가능에 가깝다

D) Rasterizer(래스터라이저) 단계
2D 모니터와 3D 공간의 최대 차이점을 꼽으라 한다면,

먼저 3D 공간은 "연속적인 무언가"로 이뤄졌다 볼 수 있음
(면, 세포, 구, 기타등등 점 하나가 아닌 연속되는 개념으로서 공간이 다뤄지고 있다)

반대로, 2D 모니터는 모니터의 각 픽셀들을 구별해 픽셀 하나하나마다 무슨 색이 들어가있나 지정하고,
그 색을 모니터에 출력하는 구조로 만들어져 있음

-> 3D 공간의 물체를 모니터에 출력하려면,
어떻게든 그 물체가 3D 공간에서 위치하고 있던 연속적인 좌표들을
2D 모니터의 픽셀/도트 좌표로 변환시키는 변환시키는 작업이 필요
이를 직접 행하는 = 위에서 폴리곤으로 갈갈이 찢어졌던 데이터를 픽셀 하나하나로 완전히 찢어서 가공하는
(Rasterize) 단계

실제로 행하는 작업은
위의 여러 단계를 통해 가공되었지만 여전히 폴리곤이라는 "도형"으로서 좌표를 다루고 있는 기존 데이터를
각 픽셀마다 대응시키는 식으로 위치를 지정해두고 "도트 단위"로 최소단위를 분해하는 단계

본격적으로 설정 하나하나를 다 뜯어볼 일은 없을 것이지만,
일부 설정을 바꾸는 일은 있을 것이기 때문에 그 때 약간 더 다둘 예정


E) Pixel Shader(픽셀 셰이더) 단계
D단계에서 픽셀 하나하나 단위로 쪼개어져 모니터의 각 픽셀에 일대일 대응이 가능해진 데이터를 받아,.
그 픽셀 하나하나마다 어떤 색을 출력할 것인지를 최종적으로 결정하는 단계
여기서 결정된 색이 최종적으로 모니터에 출력되는 색이 되는 것

이렇게 색을 결정할 때, 입력받은 데이터를 그대로 사용할 것인지
혹은 픽셀 위치 등에 따라 모자이크나 흑백, 혹은 세피아 등의 톤을 달아주는 느낌으로
필터를 설정하는지 등을 결정하는 게 가능하기에
각종 색 필터나 모자이크를 이 단계에서 구현하기도 함

Final) Output-manager 단계
모니터에 출력될 내용이 픽셀 쎼이더를 통해 전부 정해졌으면
이를 모니터에 출력하는 단계





*/